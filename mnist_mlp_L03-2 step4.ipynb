{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from utils import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, log_softmax=False):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.fc3 = nn.Linear(10, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 10)\n",
    "        self.log_softmax = log_softmax\n",
    "        self.optim = optim.SGD(self.parameters(), lr=1.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        if self.log_softmax:\n",
    "            x = F.log_softmax(x, dim=1)\n",
    "        else:\n",
    "            x = torch.log(F.softmax(x, dim=1))\n",
    "        return x\n",
    "    \n",
    "    def loss(self, output, target, **kwargs):\n",
    "        self._loss = F.nll_loss(output, target, **kwargs)\n",
    "        return self._loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, models):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        for k, model in models.items():\n",
    "            model.optim.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = model.loss(output, target)\n",
    "            loss.backward()\n",
    "            model.optim.step()\n",
    "            \n",
    "        if batch_idx % 200 == 0:\n",
    "            line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader))\n",
    "            losses = ' '.join(['{}: {:.6f}'.format(i, m._loss.item()) for i, m in models.items()])\n",
    "            print(line + losses)\n",
    "            \n",
    "    else:\n",
    "        batch_idx += 1\n",
    "        line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader))\n",
    "        losses = ' '.join(['{}: {:.6f}'.format(i, m._loss.item()) for i, m in models.items()])\n",
    "        print(line + losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, log=None):\n",
    "    test_size = len(test_loader.dataset)\n",
    "    avg_lambda = lambda l: 'Loss: {:.4f}'.format(l)\n",
    "    acc_lambda = lambda c, p: 'Accuracy: {}/{} ({:.0f}%)'.format(c, test_size, p)\n",
    "    line = lambda i, l, c, p: '{}: '.format(i) + avg_lambda(l) + '\\t' + acc_lambda(c, p)\n",
    "    \n",
    "    test_loss = {k: 0. for k in models}\n",
    "    correct = {k: 0. for k in models}\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            for k, m in models.items():\n",
    "                output = m(data)\n",
    "                test_loss[k] += m.loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "                pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                correct[k] += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "    \n",
    "    for k in models:\n",
    "        test_loss[k] /= test_size\n",
    "    correct_pct = {k: 100. * correct[k] / test_size for k in correct}\n",
    "    lines = '\\n'.join([line(i, test_loss[i], correct[i], correct_pct[i]) for i in models]) + '\\n'\n",
    "    report = 'Test set:\\n' + lines\n",
    "    if log is not None:\n",
    "        for k in models:\n",
    "            log[k].append((test_loss[k], correct_pct[k]))\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLosses softmax: 2.343302 log_softmax: 2.385403\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLosses softmax: 2.300688 log_softmax: 2.303079\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLosses softmax: 2.257360 log_softmax: 2.290816\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLosses softmax: 1.752880 log_softmax: 1.844233\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLosses softmax: 1.737638 log_softmax: 1.452388\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLosses softmax: 1.592706 log_softmax: 1.568358\n",
      "Train Epoch: 1 [60000/60000 (100%)]\tLosses softmax: 1.381296 log_softmax: 1.039642\n",
      "Test set:\n",
      "softmax: Loss: 1.3367\tAccuracy: 4464.0/10000 (45%)\n",
      "log_softmax: Loss: 1.2086\tAccuracy: 4637.0/10000 (46%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLosses softmax: 1.288479 log_softmax: 1.258459\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLosses softmax: 0.772828 log_softmax: 0.668093\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLosses softmax: 0.952145 log_softmax: 1.164183\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLosses softmax: 0.557074 log_softmax: 0.422412\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLosses softmax: 0.304256 log_softmax: 0.415626\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLosses softmax: 0.315257 log_softmax: 0.248044\n",
      "Train Epoch: 2 [60000/60000 (100%)]\tLosses softmax: 0.295195 log_softmax: 0.223587\n",
      "Test set:\n",
      "softmax: Loss: 0.3290\tAccuracy: 9208.0/10000 (92%)\n",
      "log_softmax: Loss: 0.2458\tAccuracy: 9409.0/10000 (94%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLosses softmax: 0.324713 log_softmax: 0.096418\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLosses softmax: 0.344412 log_softmax: 0.481679\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLosses softmax: 0.254601 log_softmax: 0.303435\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLosses softmax: 0.284242 log_softmax: 0.166839\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLosses softmax: 0.260810 log_softmax: 0.412603\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLosses softmax: 0.198619 log_softmax: 0.080841\n",
      "Train Epoch: 3 [60000/60000 (100%)]\tLosses softmax: 0.307970 log_softmax: 0.389464\n",
      "Test set:\n",
      "softmax: Loss: 0.1773\tAccuracy: 9554.0/10000 (96%)\n",
      "log_softmax: Loss: 0.1821\tAccuracy: 9530.0/10000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLosses softmax: 0.093206 log_softmax: 0.120768\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLosses softmax: 0.135798 log_softmax: 0.141584\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLosses softmax: 0.030269 log_softmax: 0.030331\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLosses softmax: 0.058917 log_softmax: 0.033668\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLosses softmax: 0.167234 log_softmax: 0.111978\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLosses softmax: 0.234346 log_softmax: 0.136766\n",
      "Train Epoch: 4 [60000/60000 (100%)]\tLosses softmax: 0.051609 log_softmax: 0.041542\n",
      "Test set:\n",
      "softmax: Loss: 0.1489\tAccuracy: 9619.0/10000 (96%)\n",
      "log_softmax: Loss: 0.1378\tAccuracy: 9653.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLosses softmax: 0.143458 log_softmax: 0.085465\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLosses softmax: 0.112132 log_softmax: 0.079682\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLosses softmax: 0.222303 log_softmax: 0.173080\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLosses softmax: 0.025785 log_softmax: 0.015971\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLosses softmax: 0.091475 log_softmax: 0.011933\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLosses softmax: 0.062708 log_softmax: 0.040355\n",
      "Train Epoch: 5 [60000/60000 (100%)]\tLosses softmax: 0.211821 log_softmax: 0.277703\n",
      "Test set:\n",
      "softmax: Loss: 0.1371\tAccuracy: 9643.0/10000 (96%)\n",
      "log_softmax: Loss: 0.1300\tAccuracy: 9649.0/10000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLosses softmax: 0.054287 log_softmax: 0.043752\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLosses softmax: 0.085342 log_softmax: 0.034239\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLosses softmax: 0.119815 log_softmax: 0.279214\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLosses softmax: 0.039152 log_softmax: 0.035342\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLosses softmax: 0.111765 log_softmax: 0.186534\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLosses softmax: 0.134927 log_softmax: 0.075577\n",
      "Train Epoch: 6 [60000/60000 (100%)]\tLosses softmax: 0.102299 log_softmax: 0.080387\n",
      "Test set:\n",
      "softmax: Loss: 0.1235\tAccuracy: 9676.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1195\tAccuracy: 9690.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLosses softmax: 0.034982 log_softmax: 0.056814\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLosses softmax: 0.132248 log_softmax: 0.053490\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLosses softmax: 0.013959 log_softmax: 0.022957\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLosses softmax: 0.085521 log_softmax: 0.041718\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLosses softmax: 0.043230 log_softmax: 0.184327\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLosses softmax: 0.032057 log_softmax: 0.113757\n",
      "Train Epoch: 7 [60000/60000 (100%)]\tLosses softmax: 0.069607 log_softmax: 0.079336\n",
      "Test set:\n",
      "softmax: Loss: 0.1295\tAccuracy: 9678.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1188\tAccuracy: 9689.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLosses softmax: 0.289829 log_softmax: 0.195143\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLosses softmax: 0.077568 log_softmax: 0.057165\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLosses softmax: 0.132912 log_softmax: 0.017352\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLosses softmax: 0.086843 log_softmax: 0.163865\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLosses softmax: 0.080586 log_softmax: 0.060488\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLosses softmax: 0.026496 log_softmax: 0.039091\n",
      "Train Epoch: 8 [60000/60000 (100%)]\tLosses softmax: 0.073040 log_softmax: 0.037419\n",
      "Test set:\n",
      "softmax: Loss: 0.1218\tAccuracy: 9688.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1070\tAccuracy: 9717.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLosses softmax: 0.043251 log_softmax: 0.006462\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLosses softmax: 0.202333 log_softmax: 0.108275\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLosses softmax: 0.049235 log_softmax: 0.068206\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLosses softmax: 0.005573 log_softmax: 0.025419\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLosses softmax: 0.050185 log_softmax: 0.041631\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLosses softmax: 0.091830 log_softmax: 0.027092\n",
      "Train Epoch: 9 [60000/60000 (100%)]\tLosses softmax: 0.089456 log_softmax: 0.030581\n",
      "Test set:\n",
      "softmax: Loss: 0.1075\tAccuracy: 9718.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1199\tAccuracy: 9667.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLosses softmax: 0.112226 log_softmax: 0.066168\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLosses softmax: 0.003254 log_softmax: 0.002024\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLosses softmax: 0.007770 log_softmax: 0.006289\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLosses softmax: 0.038716 log_softmax: 0.032996\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLosses softmax: 0.009600 log_softmax: 0.006508\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLosses softmax: 0.016292 log_softmax: 0.002747\n",
      "Train Epoch: 10 [60000/60000 (100%)]\tLosses softmax: 0.017506 log_softmax: 0.034060\n",
      "Test set:\n",
      "softmax: Loss: 0.1111\tAccuracy: 9710.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1168\tAccuracy: 9710.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLosses softmax: 0.033301 log_softmax: 0.055850\n",
      "Train Epoch: 11 [10000/60000 (17%)]\tLosses softmax: 0.097160 log_softmax: 0.141366\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLosses softmax: 0.003363 log_softmax: 0.002759\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLosses softmax: 0.010062 log_softmax: 0.044042\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLosses softmax: 0.012491 log_softmax: 0.014254\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLosses softmax: 0.043382 log_softmax: 0.138483\n",
      "Train Epoch: 11 [60000/60000 (100%)]\tLosses softmax: 0.088030 log_softmax: 0.057007\n",
      "Test set:\n",
      "softmax: Loss: 0.1270\tAccuracy: 9680.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1019\tAccuracy: 9735.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLosses softmax: 0.106560 log_softmax: 0.036682\n",
      "Train Epoch: 12 [10000/60000 (17%)]\tLosses softmax: 0.089398 log_softmax: 0.012149\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLosses softmax: 0.027492 log_softmax: 0.167385\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLosses softmax: 0.122399 log_softmax: 0.015811\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLosses softmax: 0.014747 log_softmax: 0.015591\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLosses softmax: 0.101304 log_softmax: 0.015779\n",
      "Train Epoch: 12 [60000/60000 (100%)]\tLosses softmax: 0.009612 log_softmax: 0.003229\n",
      "Test set:\n",
      "softmax: Loss: 0.1104\tAccuracy: 9721.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1087\tAccuracy: 9714.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLosses softmax: 0.034943 log_softmax: 0.030477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [10000/60000 (17%)]\tLosses softmax: 0.023936 log_softmax: 0.014799\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLosses softmax: 0.116289 log_softmax: 0.023361\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLosses softmax: 0.062838 log_softmax: 0.052280\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLosses softmax: 0.028335 log_softmax: 0.225444\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLosses softmax: 0.017341 log_softmax: 0.032511\n",
      "Train Epoch: 13 [60000/60000 (100%)]\tLosses softmax: 0.017899 log_softmax: 0.009934\n",
      "Test set:\n",
      "softmax: Loss: 0.1062\tAccuracy: 9720.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1367\tAccuracy: 9655.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLosses softmax: 0.008664 log_softmax: 0.036440\n",
      "Train Epoch: 14 [10000/60000 (17%)]\tLosses softmax: 0.227982 log_softmax: 0.018900\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLosses softmax: 0.097456 log_softmax: 0.152759\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLosses softmax: 0.004154 log_softmax: 0.002438\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLosses softmax: 0.139350 log_softmax: 0.019504\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLosses softmax: 0.002762 log_softmax: 0.001372\n",
      "Train Epoch: 14 [60000/60000 (100%)]\tLosses softmax: 0.007907 log_softmax: 0.031665\n",
      "Test set:\n",
      "softmax: Loss: 0.1170\tAccuracy: 9719.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1272\tAccuracy: 9677.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLosses softmax: 0.002389 log_softmax: 0.016168\n",
      "Train Epoch: 15 [10000/60000 (17%)]\tLosses softmax: 0.032403 log_softmax: 0.002448\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLosses softmax: 0.001939 log_softmax: 0.049069\n",
      "Train Epoch: 15 [30000/60000 (50%)]\tLosses softmax: 0.007571 log_softmax: 0.006135\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLosses softmax: 0.003610 log_softmax: 0.011938\n",
      "Train Epoch: 15 [50000/60000 (83%)]\tLosses softmax: 0.007472 log_softmax: 0.016891\n",
      "Train Epoch: 15 [60000/60000 (100%)]\tLosses softmax: 0.007817 log_softmax: 0.006058\n",
      "Test set:\n",
      "softmax: Loss: 0.1092\tAccuracy: 9731.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1156\tAccuracy: 9721.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLosses softmax: 0.003591 log_softmax: 0.003352\n",
      "Train Epoch: 16 [10000/60000 (17%)]\tLosses softmax: 0.003986 log_softmax: 0.009200\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLosses softmax: 0.004261 log_softmax: 0.007795\n",
      "Train Epoch: 16 [30000/60000 (50%)]\tLosses softmax: 0.001021 log_softmax: 0.002444\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLosses softmax: 0.015545 log_softmax: 0.005060\n",
      "Train Epoch: 16 [50000/60000 (83%)]\tLosses softmax: 0.024265 log_softmax: 0.029831\n",
      "Train Epoch: 16 [60000/60000 (100%)]\tLosses softmax: 0.009211 log_softmax: 0.016443\n",
      "Test set:\n",
      "softmax: Loss: 0.1254\tAccuracy: 9711.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1266\tAccuracy: 9703.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLosses softmax: 0.001349 log_softmax: 0.105360\n",
      "Train Epoch: 17 [10000/60000 (17%)]\tLosses softmax: 0.036268 log_softmax: 0.025270\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLosses softmax: 0.007546 log_softmax: 0.007821\n",
      "Train Epoch: 17 [30000/60000 (50%)]\tLosses softmax: 0.007951 log_softmax: 0.057899\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLosses softmax: 0.012050 log_softmax: 0.001685\n",
      "Train Epoch: 17 [50000/60000 (83%)]\tLosses softmax: 0.138468 log_softmax: 0.008457\n",
      "Train Epoch: 17 [60000/60000 (100%)]\tLosses softmax: 0.003205 log_softmax: 0.020098\n",
      "Test set:\n",
      "softmax: Loss: 0.1162\tAccuracy: 9731.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1143\tAccuracy: 9738.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLosses softmax: 0.003556 log_softmax: 0.014642\n",
      "Train Epoch: 18 [10000/60000 (17%)]\tLosses softmax: 0.145801 log_softmax: 0.013842\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLosses softmax: 0.001711 log_softmax: 0.001554\n",
      "Train Epoch: 18 [30000/60000 (50%)]\tLosses softmax: 0.005301 log_softmax: 0.015037\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLosses softmax: 0.038019 log_softmax: 0.016288\n",
      "Train Epoch: 18 [50000/60000 (83%)]\tLosses softmax: 0.008825 log_softmax: 0.008712\n",
      "Train Epoch: 18 [60000/60000 (100%)]\tLosses softmax: 0.001345 log_softmax: 0.003697\n",
      "Test set:\n",
      "softmax: Loss: 0.1256\tAccuracy: 9706.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1130\tAccuracy: 9734.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLosses softmax: 0.029326 log_softmax: 0.036699\n",
      "Train Epoch: 19 [10000/60000 (17%)]\tLosses softmax: 0.036652 log_softmax: 0.010274\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLosses softmax: 0.004242 log_softmax: 0.078028\n",
      "Train Epoch: 19 [30000/60000 (50%)]\tLosses softmax: 0.004022 log_softmax: 0.005294\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLosses softmax: 0.000971 log_softmax: 0.004424\n",
      "Train Epoch: 19 [50000/60000 (83%)]\tLosses softmax: 0.024306 log_softmax: 0.003350\n",
      "Train Epoch: 19 [60000/60000 (100%)]\tLosses softmax: 0.111190 log_softmax: 0.064208\n",
      "Test set:\n",
      "softmax: Loss: 0.1368\tAccuracy: 9699.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1176\tAccuracy: 9744.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLosses softmax: 0.002879 log_softmax: 0.001375\n",
      "Train Epoch: 20 [10000/60000 (17%)]\tLosses softmax: 0.035968 log_softmax: 0.001294\n",
      "Train Epoch: 20 [20000/60000 (33%)]\tLosses softmax: 0.011799 log_softmax: 0.011283\n",
      "Train Epoch: 20 [30000/60000 (50%)]\tLosses softmax: 0.001291 log_softmax: 0.003651\n",
      "Train Epoch: 20 [40000/60000 (67%)]\tLosses softmax: 0.021938 log_softmax: 0.004019\n",
      "Train Epoch: 20 [50000/60000 (83%)]\tLosses softmax: 0.000568 log_softmax: 0.000479\n",
      "Train Epoch: 20 [60000/60000 (100%)]\tLosses softmax: 0.003780 log_softmax: 0.008018\n",
      "Test set:\n",
      "softmax: Loss: 0.1117\tAccuracy: 9735.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1300\tAccuracy: 9702.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLosses softmax: 0.006326 log_softmax: 0.004686\n",
      "Train Epoch: 21 [10000/60000 (17%)]\tLosses softmax: 0.002175 log_softmax: 0.004472\n",
      "Train Epoch: 21 [20000/60000 (33%)]\tLosses softmax: 0.038048 log_softmax: 0.026504\n",
      "Train Epoch: 21 [30000/60000 (50%)]\tLosses softmax: 0.032419 log_softmax: 0.035082\n",
      "Train Epoch: 21 [40000/60000 (67%)]\tLosses softmax: 0.000752 log_softmax: 0.010008\n",
      "Train Epoch: 21 [50000/60000 (83%)]\tLosses softmax: 0.019504 log_softmax: 0.011843\n",
      "Train Epoch: 21 [60000/60000 (100%)]\tLosses softmax: 0.002198 log_softmax: 0.001279\n",
      "Test set:\n",
      "softmax: Loss: 0.1149\tAccuracy: 9728.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1200\tAccuracy: 9732.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLosses softmax: 0.005191 log_softmax: 0.001744\n",
      "Train Epoch: 22 [10000/60000 (17%)]\tLosses softmax: 0.002248 log_softmax: 0.003296\n",
      "Train Epoch: 22 [20000/60000 (33%)]\tLosses softmax: 0.020251 log_softmax: 0.010354\n",
      "Train Epoch: 22 [30000/60000 (50%)]\tLosses softmax: 0.001623 log_softmax: 0.001298\n",
      "Train Epoch: 22 [40000/60000 (67%)]\tLosses softmax: 0.001684 log_softmax: 0.000703\n",
      "Train Epoch: 22 [50000/60000 (83%)]\tLosses softmax: 0.027499 log_softmax: 0.026736\n",
      "Train Epoch: 22 [60000/60000 (100%)]\tLosses softmax: 0.019690 log_softmax: 0.037696\n",
      "Test set:\n",
      "softmax: Loss: 0.1106\tAccuracy: 9755.0/10000 (98%)\n",
      "log_softmax: Loss: 0.1125\tAccuracy: 9752.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLosses softmax: 0.001021 log_softmax: 0.002025\n",
      "Train Epoch: 23 [10000/60000 (17%)]\tLosses softmax: 0.036032 log_softmax: 0.001261\n",
      "Train Epoch: 23 [20000/60000 (33%)]\tLosses softmax: 0.016012 log_softmax: 0.053796\n",
      "Train Epoch: 23 [30000/60000 (50%)]\tLosses softmax: 0.011297 log_softmax: 0.007473\n",
      "Train Epoch: 23 [40000/60000 (67%)]\tLosses softmax: 0.041877 log_softmax: 0.005809\n",
      "Train Epoch: 23 [50000/60000 (83%)]\tLosses softmax: 0.002399 log_softmax: 0.007122\n",
      "Train Epoch: 23 [60000/60000 (100%)]\tLosses softmax: 0.001687 log_softmax: 0.004537\n",
      "Test set:\n",
      "softmax: Loss: 0.1201\tAccuracy: 9737.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1215\tAccuracy: 9739.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLosses softmax: 0.003365 log_softmax: 0.000992\n",
      "Train Epoch: 24 [10000/60000 (17%)]\tLosses softmax: 0.002794 log_softmax: 0.002581\n",
      "Train Epoch: 24 [20000/60000 (33%)]\tLosses softmax: 0.014496 log_softmax: 0.000809\n",
      "Train Epoch: 24 [30000/60000 (50%)]\tLosses softmax: 0.002238 log_softmax: 0.008532\n",
      "Train Epoch: 24 [40000/60000 (67%)]\tLosses softmax: 0.035739 log_softmax: 0.005935\n",
      "Train Epoch: 24 [50000/60000 (83%)]\tLosses softmax: 0.016113 log_softmax: 0.000991\n",
      "Train Epoch: 24 [60000/60000 (100%)]\tLosses softmax: 0.101574 log_softmax: 0.002893\n",
      "Test set:\n",
      "softmax: Loss: 0.1190\tAccuracy: 9744.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1270\tAccuracy: 9713.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLosses softmax: 0.004839 log_softmax: 0.008752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [10000/60000 (17%)]\tLosses softmax: 0.001133 log_softmax: 0.000313\n",
      "Train Epoch: 25 [20000/60000 (33%)]\tLosses softmax: 0.001496 log_softmax: 0.000783\n",
      "Train Epoch: 25 [30000/60000 (50%)]\tLosses softmax: 0.047640 log_softmax: 0.001844\n",
      "Train Epoch: 25 [40000/60000 (67%)]\tLosses softmax: 0.001034 log_softmax: 0.002255\n",
      "Train Epoch: 25 [50000/60000 (83%)]\tLosses softmax: 0.023928 log_softmax: 0.040604\n",
      "Train Epoch: 25 [60000/60000 (100%)]\tLosses softmax: 0.023793 log_softmax: 0.000794\n",
      "Test set:\n",
      "softmax: Loss: 0.1240\tAccuracy: 9748.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1250\tAccuracy: 9730.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLosses softmax: 0.055151 log_softmax: 0.156752\n",
      "Train Epoch: 26 [10000/60000 (17%)]\tLosses softmax: 0.007041 log_softmax: 0.006195\n",
      "Train Epoch: 26 [20000/60000 (33%)]\tLosses softmax: 0.001409 log_softmax: 0.109516\n",
      "Train Epoch: 26 [30000/60000 (50%)]\tLosses softmax: 0.001496 log_softmax: 0.026097\n",
      "Train Epoch: 26 [40000/60000 (67%)]\tLosses softmax: 0.002615 log_softmax: 0.004029\n",
      "Train Epoch: 26 [50000/60000 (83%)]\tLosses softmax: 0.001822 log_softmax: 0.029470\n",
      "Train Epoch: 26 [60000/60000 (100%)]\tLosses softmax: 0.011968 log_softmax: 0.014017\n",
      "Test set:\n",
      "softmax: Loss: 0.1263\tAccuracy: 9738.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1135\tAccuracy: 9754.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLosses softmax: 0.091664 log_softmax: 0.088995\n",
      "Train Epoch: 27 [10000/60000 (17%)]\tLosses softmax: 0.000427 log_softmax: 0.010233\n",
      "Train Epoch: 27 [20000/60000 (33%)]\tLosses softmax: 0.000474 log_softmax: 0.001738\n",
      "Train Epoch: 27 [30000/60000 (50%)]\tLosses softmax: 0.051676 log_softmax: 0.004476\n",
      "Train Epoch: 27 [40000/60000 (67%)]\tLosses softmax: 0.001029 log_softmax: 0.010843\n",
      "Train Epoch: 27 [50000/60000 (83%)]\tLosses softmax: 0.015584 log_softmax: 0.104863\n",
      "Train Epoch: 27 [60000/60000 (100%)]\tLosses softmax: 0.015060 log_softmax: 0.003564\n",
      "Test set:\n",
      "softmax: Loss: 0.1318\tAccuracy: 9729.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1227\tAccuracy: 9722.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLosses softmax: 0.000753 log_softmax: 0.003414\n",
      "Train Epoch: 28 [10000/60000 (17%)]\tLosses softmax: 0.001789 log_softmax: 0.002365\n",
      "Train Epoch: 28 [20000/60000 (33%)]\tLosses softmax: 0.003475 log_softmax: 0.005802\n",
      "Train Epoch: 28 [30000/60000 (50%)]\tLosses softmax: 0.008305 log_softmax: 0.003697\n",
      "Train Epoch: 28 [40000/60000 (67%)]\tLosses softmax: 0.000814 log_softmax: 0.000991\n",
      "Train Epoch: 28 [50000/60000 (83%)]\tLosses softmax: 0.003492 log_softmax: 0.001244\n",
      "Train Epoch: 28 [60000/60000 (100%)]\tLosses softmax: 0.000693 log_softmax: 0.008059\n",
      "Test set:\n",
      "softmax: Loss: 0.1192\tAccuracy: 9771.0/10000 (98%)\n",
      "log_softmax: Loss: 0.1168\tAccuracy: 9746.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLosses softmax: 0.035793 log_softmax: 0.004003\n",
      "Train Epoch: 29 [10000/60000 (17%)]\tLosses softmax: 0.002447 log_softmax: 0.043089\n",
      "Train Epoch: 29 [20000/60000 (33%)]\tLosses softmax: 0.001537 log_softmax: 0.046032\n",
      "Train Epoch: 29 [30000/60000 (50%)]\tLosses softmax: 0.005678 log_softmax: 0.009921\n",
      "Train Epoch: 29 [40000/60000 (67%)]\tLosses softmax: 0.022189 log_softmax: 0.002469\n",
      "Train Epoch: 29 [50000/60000 (83%)]\tLosses softmax: 0.001125 log_softmax: 0.000549\n",
      "Train Epoch: 29 [60000/60000 (100%)]\tLosses softmax: 0.007905 log_softmax: 0.001368\n",
      "Test set:\n",
      "softmax: Loss: 0.1379\tAccuracy: 9720.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1218\tAccuracy: 9743.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLosses softmax: 0.001262 log_softmax: 0.000656\n",
      "Train Epoch: 30 [10000/60000 (17%)]\tLosses softmax: 0.000249 log_softmax: 0.005303\n",
      "Train Epoch: 30 [20000/60000 (33%)]\tLosses softmax: 0.007193 log_softmax: 0.003159\n",
      "Train Epoch: 30 [30000/60000 (50%)]\tLosses softmax: 0.001510 log_softmax: 0.021606\n",
      "Train Epoch: 30 [40000/60000 (67%)]\tLosses softmax: 0.000544 log_softmax: 0.124264\n",
      "Train Epoch: 30 [50000/60000 (83%)]\tLosses softmax: 0.125546 log_softmax: 0.012813\n",
      "Train Epoch: 30 [60000/60000 (100%)]\tLosses softmax: 0.000245 log_softmax: 0.036381\n",
      "Test set:\n",
      "softmax: Loss: 0.1331\tAccuracy: 9724.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1335\tAccuracy: 9728.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLosses softmax: 0.012828 log_softmax: 0.007757\n",
      "Train Epoch: 31 [10000/60000 (17%)]\tLosses softmax: 0.091609 log_softmax: 0.000594\n",
      "Train Epoch: 31 [20000/60000 (33%)]\tLosses softmax: 0.000623 log_softmax: 0.002550\n",
      "Train Epoch: 31 [30000/60000 (50%)]\tLosses softmax: 0.025926 log_softmax: 0.009175\n",
      "Train Epoch: 31 [40000/60000 (67%)]\tLosses softmax: 0.009715 log_softmax: 0.001611\n",
      "Train Epoch: 31 [50000/60000 (83%)]\tLosses softmax: 0.001173 log_softmax: 0.000925\n",
      "Train Epoch: 31 [60000/60000 (100%)]\tLosses softmax: 0.001680 log_softmax: 0.000578\n",
      "Test set:\n",
      "softmax: Loss: 0.1249\tAccuracy: 9741.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1481\tAccuracy: 9695.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLosses softmax: 0.000942 log_softmax: 0.009682\n",
      "Train Epoch: 32 [10000/60000 (17%)]\tLosses softmax: 0.000366 log_softmax: 0.000398\n",
      "Train Epoch: 32 [20000/60000 (33%)]\tLosses softmax: 0.002064 log_softmax: 0.047990\n",
      "Train Epoch: 32 [30000/60000 (50%)]\tLosses softmax: 0.001142 log_softmax: 0.009940\n",
      "Train Epoch: 32 [40000/60000 (67%)]\tLosses softmax: 0.005215 log_softmax: 0.002130\n",
      "Train Epoch: 32 [50000/60000 (83%)]\tLosses softmax: 0.000885 log_softmax: 0.011788\n",
      "Train Epoch: 32 [60000/60000 (100%)]\tLosses softmax: 0.000680 log_softmax: 0.001100\n",
      "Test set:\n",
      "softmax: Loss: 0.1179\tAccuracy: 9761.0/10000 (98%)\n",
      "log_softmax: Loss: 0.1470\tAccuracy: 9716.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLosses softmax: 0.000501 log_softmax: 0.026166\n",
      "Train Epoch: 33 [10000/60000 (17%)]\tLosses softmax: 0.001095 log_softmax: 0.029069\n",
      "Train Epoch: 33 [20000/60000 (33%)]\tLosses softmax: 0.000372 log_softmax: 0.006226\n",
      "Train Epoch: 33 [30000/60000 (50%)]\tLosses softmax: 0.001068 log_softmax: 0.006381\n",
      "Train Epoch: 33 [40000/60000 (67%)]\tLosses softmax: 0.027267 log_softmax: 0.008610\n",
      "Train Epoch: 33 [50000/60000 (83%)]\tLosses softmax: 0.000309 log_softmax: 0.000353\n",
      "Train Epoch: 33 [60000/60000 (100%)]\tLosses softmax: 0.008297 log_softmax: 0.003054\n",
      "Test set:\n",
      "softmax: Loss: 0.1172\tAccuracy: 9746.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1285\tAccuracy: 9725.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLosses softmax: 0.002607 log_softmax: 0.000588\n",
      "Train Epoch: 34 [10000/60000 (17%)]\tLosses softmax: 0.000948 log_softmax: 0.000425\n",
      "Train Epoch: 34 [20000/60000 (33%)]\tLosses softmax: 0.001202 log_softmax: 0.002860\n",
      "Train Epoch: 34 [30000/60000 (50%)]\tLosses softmax: 0.000393 log_softmax: 0.000569\n",
      "Train Epoch: 34 [40000/60000 (67%)]\tLosses softmax: 0.019945 log_softmax: 0.003837\n",
      "Train Epoch: 34 [50000/60000 (83%)]\tLosses softmax: 0.006202 log_softmax: 0.005259\n",
      "Train Epoch: 34 [60000/60000 (100%)]\tLosses softmax: 0.033468 log_softmax: 0.004317\n",
      "Test set:\n",
      "softmax: Loss: 0.1187\tAccuracy: 9739.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1202\tAccuracy: 9738.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLosses softmax: 0.001256 log_softmax: 0.004326\n",
      "Train Epoch: 35 [10000/60000 (17%)]\tLosses softmax: 0.000613 log_softmax: 0.000280\n",
      "Train Epoch: 35 [20000/60000 (33%)]\tLosses softmax: 0.109471 log_softmax: 0.002070\n",
      "Train Epoch: 35 [30000/60000 (50%)]\tLosses softmax: 0.000782 log_softmax: 0.000322\n",
      "Train Epoch: 35 [40000/60000 (67%)]\tLosses softmax: 0.000636 log_softmax: 0.014824\n",
      "Train Epoch: 35 [50000/60000 (83%)]\tLosses softmax: 0.006813 log_softmax: 0.026629\n",
      "Train Epoch: 35 [60000/60000 (100%)]\tLosses softmax: 0.030526 log_softmax: 0.003767\n",
      "Test set:\n",
      "softmax: Loss: 0.1213\tAccuracy: 9749.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1240\tAccuracy: 9742.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLosses softmax: 0.015954 log_softmax: 0.011751\n",
      "Train Epoch: 36 [10000/60000 (17%)]\tLosses softmax: 0.025226 log_softmax: 0.000734\n",
      "Train Epoch: 36 [20000/60000 (33%)]\tLosses softmax: 0.003605 log_softmax: 0.000908\n",
      "Train Epoch: 36 [30000/60000 (50%)]\tLosses softmax: 0.001023 log_softmax: 0.020926\n",
      "Train Epoch: 36 [40000/60000 (67%)]\tLosses softmax: 0.000196 log_softmax: 0.000427\n",
      "Train Epoch: 36 [50000/60000 (83%)]\tLosses softmax: 0.001255 log_softmax: 0.002451\n",
      "Train Epoch: 36 [60000/60000 (100%)]\tLosses softmax: 0.000249 log_softmax: 0.000814\n",
      "Test set:\n",
      "softmax: Loss: 0.1477\tAccuracy: 9717.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1213\tAccuracy: 9731.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLosses softmax: 0.002800 log_softmax: 0.000373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 [10000/60000 (17%)]\tLosses softmax: 0.002340 log_softmax: 0.000554\n",
      "Train Epoch: 37 [20000/60000 (33%)]\tLosses softmax: 0.004113 log_softmax: 0.029551\n",
      "Train Epoch: 37 [30000/60000 (50%)]\tLosses softmax: 0.032687 log_softmax: 0.001188\n",
      "Train Epoch: 37 [40000/60000 (67%)]\tLosses softmax: 0.004397 log_softmax: 0.005159\n",
      "Train Epoch: 37 [50000/60000 (83%)]\tLosses softmax: 0.004916 log_softmax: 0.001173\n",
      "Train Epoch: 37 [60000/60000 (100%)]\tLosses softmax: 0.005042 log_softmax: 0.001837\n",
      "Test set:\n",
      "softmax: Loss: 0.1223\tAccuracy: 9764.0/10000 (98%)\n",
      "log_softmax: Loss: 0.1218\tAccuracy: 9734.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLosses softmax: 0.000582 log_softmax: 0.001696\n",
      "Train Epoch: 38 [10000/60000 (17%)]\tLosses softmax: 0.000426 log_softmax: 0.001079\n",
      "Train Epoch: 38 [20000/60000 (33%)]\tLosses softmax: 0.000283 log_softmax: 0.001816\n",
      "Train Epoch: 38 [30000/60000 (50%)]\tLosses softmax: 0.001413 log_softmax: 0.004438\n",
      "Train Epoch: 38 [40000/60000 (67%)]\tLosses softmax: 0.000629 log_softmax: 0.002543\n",
      "Train Epoch: 38 [50000/60000 (83%)]\tLosses softmax: 0.000564 log_softmax: 0.001899\n",
      "Train Epoch: 38 [60000/60000 (100%)]\tLosses softmax: 0.003120 log_softmax: 0.052125\n",
      "Test set:\n",
      "softmax: Loss: 0.1288\tAccuracy: 9761.0/10000 (98%)\n",
      "log_softmax: Loss: 0.1405\tAccuracy: 9700.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLosses softmax: 0.000253 log_softmax: 0.000433\n",
      "Train Epoch: 39 [10000/60000 (17%)]\tLosses softmax: 0.001096 log_softmax: 0.118709\n",
      "Train Epoch: 39 [20000/60000 (33%)]\tLosses softmax: 0.000388 log_softmax: 0.003690\n",
      "Train Epoch: 39 [30000/60000 (50%)]\tLosses softmax: 0.014725 log_softmax: 0.101333\n",
      "Train Epoch: 39 [40000/60000 (67%)]\tLosses softmax: 0.001720 log_softmax: 0.003471\n",
      "Train Epoch: 39 [50000/60000 (83%)]\tLosses softmax: 0.000671 log_softmax: 0.001839\n",
      "Train Epoch: 39 [60000/60000 (100%)]\tLosses softmax: 0.067654 log_softmax: 0.001597\n",
      "Test set:\n",
      "softmax: Loss: 0.1535\tAccuracy: 9698.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1353\tAccuracy: 9727.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLosses softmax: 0.016469 log_softmax: 0.095128\n",
      "Train Epoch: 40 [10000/60000 (17%)]\tLosses softmax: 0.000276 log_softmax: 0.000309\n",
      "Train Epoch: 40 [20000/60000 (33%)]\tLosses softmax: 0.003785 log_softmax: 0.018039\n",
      "Train Epoch: 40 [30000/60000 (50%)]\tLosses softmax: 0.000726 log_softmax: 0.054960\n",
      "Train Epoch: 40 [40000/60000 (67%)]\tLosses softmax: 0.003701 log_softmax: 0.001282\n",
      "Train Epoch: 40 [50000/60000 (83%)]\tLosses softmax: 0.002364 log_softmax: 0.006070\n",
      "Train Epoch: 40 [60000/60000 (100%)]\tLosses softmax: 0.006888 log_softmax: 0.014542\n",
      "Test set:\n",
      "softmax: Loss: 0.1540\tAccuracy: 9706.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1294\tAccuracy: 9737.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLosses softmax: 0.002171 log_softmax: 0.001207\n",
      "Train Epoch: 41 [10000/60000 (17%)]\tLosses softmax: 0.000348 log_softmax: 0.003222\n",
      "Train Epoch: 41 [20000/60000 (33%)]\tLosses softmax: 0.000237 log_softmax: 0.002812\n",
      "Train Epoch: 41 [30000/60000 (50%)]\tLosses softmax: 0.000297 log_softmax: 0.003997\n",
      "Train Epoch: 41 [40000/60000 (67%)]\tLosses softmax: 0.001631 log_softmax: 0.013639\n",
      "Train Epoch: 41 [50000/60000 (83%)]\tLosses softmax: 0.000489 log_softmax: 0.003415\n",
      "Train Epoch: 41 [60000/60000 (100%)]\tLosses softmax: 0.003733 log_softmax: 0.007996\n",
      "Test set:\n",
      "softmax: Loss: 0.1425\tAccuracy: 9720.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1181\tAccuracy: 9746.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLosses softmax: 0.001507 log_softmax: 0.000599\n",
      "Train Epoch: 42 [10000/60000 (17%)]\tLosses softmax: 0.001931 log_softmax: 0.002399\n",
      "Train Epoch: 42 [20000/60000 (33%)]\tLosses softmax: 0.007619 log_softmax: 0.003314\n",
      "Train Epoch: 42 [30000/60000 (50%)]\tLosses softmax: 0.000310 log_softmax: 0.000473\n",
      "Train Epoch: 42 [40000/60000 (67%)]\tLosses softmax: 0.000730 log_softmax: 0.001759\n",
      "Train Epoch: 42 [50000/60000 (83%)]\tLosses softmax: 0.000353 log_softmax: 0.005004\n",
      "Train Epoch: 42 [60000/60000 (100%)]\tLosses softmax: 0.003836 log_softmax: 0.013312\n",
      "Test set:\n",
      "softmax: Loss: 0.1382\tAccuracy: 9760.0/10000 (98%)\n",
      "log_softmax: Loss: 0.1329\tAccuracy: 9724.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLosses softmax: 0.000878 log_softmax: 0.001041\n",
      "Train Epoch: 43 [10000/60000 (17%)]\tLosses softmax: 0.007444 log_softmax: 0.009645\n",
      "Train Epoch: 43 [20000/60000 (33%)]\tLosses softmax: 0.004397 log_softmax: 0.000498\n",
      "Train Epoch: 43 [30000/60000 (50%)]\tLosses softmax: 0.000962 log_softmax: 0.000926\n",
      "Train Epoch: 43 [40000/60000 (67%)]\tLosses softmax: 0.000249 log_softmax: 0.000222\n",
      "Train Epoch: 43 [50000/60000 (83%)]\tLosses softmax: 0.000583 log_softmax: 0.001292\n",
      "Train Epoch: 43 [60000/60000 (100%)]\tLosses softmax: 0.001969 log_softmax: 0.001252\n",
      "Test set:\n",
      "softmax: Loss: 0.1412\tAccuracy: 9726.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1165\tAccuracy: 9769.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLosses softmax: 0.001085 log_softmax: 0.003241\n",
      "Train Epoch: 44 [10000/60000 (17%)]\tLosses softmax: 0.000439 log_softmax: 0.001400\n",
      "Train Epoch: 44 [20000/60000 (33%)]\tLosses softmax: 0.001440 log_softmax: 0.073895\n",
      "Train Epoch: 44 [30000/60000 (50%)]\tLosses softmax: 0.016902 log_softmax: 0.000915\n",
      "Train Epoch: 44 [40000/60000 (67%)]\tLosses softmax: 0.000658 log_softmax: 0.008431\n",
      "Train Epoch: 44 [50000/60000 (83%)]\tLosses softmax: 0.000699 log_softmax: 0.001181\n",
      "Train Epoch: 44 [60000/60000 (100%)]\tLosses softmax: 0.003460 log_softmax: 0.011132\n",
      "Test set:\n",
      "softmax: Loss: 0.1390\tAccuracy: 9741.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1231\tAccuracy: 9742.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLosses softmax: 0.000153 log_softmax: 0.002294\n",
      "Train Epoch: 45 [10000/60000 (17%)]\tLosses softmax: 0.041629 log_softmax: 0.000687\n",
      "Train Epoch: 45 [20000/60000 (33%)]\tLosses softmax: 0.000524 log_softmax: 0.005104\n",
      "Train Epoch: 45 [30000/60000 (50%)]\tLosses softmax: 0.001180 log_softmax: 0.000423\n",
      "Train Epoch: 45 [40000/60000 (67%)]\tLosses softmax: 0.001629 log_softmax: 0.001188\n",
      "Train Epoch: 45 [50000/60000 (83%)]\tLosses softmax: 0.001183 log_softmax: 0.000797\n",
      "Train Epoch: 45 [60000/60000 (100%)]\tLosses softmax: 0.027031 log_softmax: 0.001196\n",
      "Test set:\n",
      "softmax: Loss: 0.1430\tAccuracy: 9729.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1205\tAccuracy: 9751.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLosses softmax: 0.002918 log_softmax: 0.041187\n",
      "Train Epoch: 46 [10000/60000 (17%)]\tLosses softmax: 0.008130 log_softmax: 0.038383\n",
      "Train Epoch: 46 [20000/60000 (33%)]\tLosses softmax: 0.010786 log_softmax: 0.002977\n",
      "Train Epoch: 46 [30000/60000 (50%)]\tLosses softmax: 0.001249 log_softmax: 0.008227\n",
      "Train Epoch: 46 [40000/60000 (67%)]\tLosses softmax: 0.000639 log_softmax: 0.000283\n",
      "Train Epoch: 46 [50000/60000 (83%)]\tLosses softmax: 0.059799 log_softmax: 0.007330\n",
      "Train Epoch: 46 [60000/60000 (100%)]\tLosses softmax: 0.000350 log_softmax: 0.036613\n",
      "Test set:\n",
      "softmax: Loss: 0.1216\tAccuracy: 9761.0/10000 (98%)\n",
      "log_softmax: Loss: 0.1253\tAccuracy: 9755.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLosses softmax: 0.000330 log_softmax: 0.001067\n",
      "Train Epoch: 47 [10000/60000 (17%)]\tLosses softmax: 0.000582 log_softmax: 0.001405\n",
      "Train Epoch: 47 [20000/60000 (33%)]\tLosses softmax: 0.000399 log_softmax: 0.000252\n",
      "Train Epoch: 47 [30000/60000 (50%)]\tLosses softmax: 0.000488 log_softmax: 0.000203\n",
      "Train Epoch: 47 [40000/60000 (67%)]\tLosses softmax: 0.017144 log_softmax: 0.032915\n",
      "Train Epoch: 47 [50000/60000 (83%)]\tLosses softmax: 0.004030 log_softmax: 0.001059\n",
      "Train Epoch: 47 [60000/60000 (100%)]\tLosses softmax: 0.000197 log_softmax: 0.002412\n",
      "Test set:\n",
      "softmax: Loss: 0.1266\tAccuracy: 9768.0/10000 (98%)\n",
      "log_softmax: Loss: 0.1256\tAccuracy: 9747.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLosses softmax: 0.005728 log_softmax: 0.010682\n",
      "Train Epoch: 48 [10000/60000 (17%)]\tLosses softmax: 0.000398 log_softmax: 0.001797\n",
      "Train Epoch: 48 [20000/60000 (33%)]\tLosses softmax: 0.002695 log_softmax: 0.007591\n",
      "Train Epoch: 48 [30000/60000 (50%)]\tLosses softmax: 0.122521 log_softmax: 0.121440\n",
      "Train Epoch: 48 [40000/60000 (67%)]\tLosses softmax: 0.000151 log_softmax: 0.008206\n",
      "Train Epoch: 48 [50000/60000 (83%)]\tLosses softmax: 0.010715 log_softmax: 0.001730\n",
      "Train Epoch: 48 [60000/60000 (100%)]\tLosses softmax: 0.072947 log_softmax: 0.013476\n",
      "Test set:\n",
      "softmax: Loss: 0.1327\tAccuracy: 9747.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1371\tAccuracy: 9729.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLosses softmax: 0.002405 log_softmax: 0.000385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 49 [10000/60000 (17%)]\tLosses softmax: 0.000726 log_softmax: 0.001663\n",
      "Train Epoch: 49 [20000/60000 (33%)]\tLosses softmax: 0.022940 log_softmax: 0.005381\n",
      "Train Epoch: 49 [30000/60000 (50%)]\tLosses softmax: 0.001873 log_softmax: 0.003375\n",
      "Train Epoch: 49 [40000/60000 (67%)]\tLosses softmax: 0.003024 log_softmax: 0.000689\n",
      "Train Epoch: 49 [50000/60000 (83%)]\tLosses softmax: 0.000681 log_softmax: 0.059927\n",
      "Train Epoch: 49 [60000/60000 (100%)]\tLosses softmax: 0.000244 log_softmax: 0.007998\n",
      "Test set:\n",
      "softmax: Loss: 0.1394\tAccuracy: 9748.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1246\tAccuracy: 9745.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLosses softmax: 0.000126 log_softmax: 0.000384\n",
      "Train Epoch: 50 [10000/60000 (17%)]\tLosses softmax: 0.001383 log_softmax: 0.013121\n",
      "Train Epoch: 50 [20000/60000 (33%)]\tLosses softmax: 0.003427 log_softmax: 0.001350\n",
      "Train Epoch: 50 [30000/60000 (50%)]\tLosses softmax: 0.000546 log_softmax: 0.013611\n",
      "Train Epoch: 50 [40000/60000 (67%)]\tLosses softmax: 0.000141 log_softmax: 0.001824\n",
      "Train Epoch: 50 [50000/60000 (83%)]\tLosses softmax: 0.000234 log_softmax: 0.000891\n",
      "Train Epoch: 50 [60000/60000 (100%)]\tLosses softmax: 0.000129 log_softmax: 0.073588\n",
      "Test set:\n",
      "softmax: Loss: 0.1311\tAccuracy: 9739.0/10000 (97%)\n",
      "log_softmax: Loss: 0.1283\tAccuracy: 9755.0/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {'softmax' : Net(), 'log_softmax' : Net(True)}\n",
    "test_log = {k: [] for k in models}\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(1, epochs+1):\n",
    "    for model in models.values():\n",
    "        model.train()\n",
    "    train(epoch, models)\n",
    "    for model in models.values():\n",
    "        model.eval()\n",
    "    test(models, test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loss_softmax = [i[0] for i in test_log['softmax']]\n",
    "test_acc_softmax = [i[1] for i in test_log['softmax']]\n",
    "test_loss_log_softmax = [i[0] for i in test_log['log_softmax']]\n",
    "test_acc_log_softmax = [i[1] for i in test_log['log_softmax']]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(range(0, epochs), test_loss_softmax)\n",
    "plt.xticks(range(0, epochs, 2))\n",
    "plt.xlim((0, 50))\n",
    "# plt.ylim((0.06, 0.13))\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(range(0, epochs), test_acc_softmax)\n",
    "plt.xlabel('epochs')\n",
    "plt.xticks(range(0, epochs, 2))\n",
    "plt.xlim((0, 50))\n",
    "# plt.ylim((96, 98.5))\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13112350215446203"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss_softmax[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
